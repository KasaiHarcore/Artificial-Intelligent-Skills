{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss was introduced to address the class imbalance problem in tasks like object detection. In highly imbalanced datasets, standard loss functions (e.g., cross-entropy) can become biased toward the majority class. Focal loss mitigates this by focusing more on hard-to-classify examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focal Loss extends the cross-entropy loss by adding a **modulating factor** to down-weight easy examples and focus on hard misclassified cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematically**, the focal loss is defined as: (binary classification)\n",
    "\n",
    "$$\\mathrm{L}(y, \\hat{y}) = -\\alpha (1 - \\hat{y})^\\gamma \\log(\\hat{y}) - (1 - \\alpha) \\hat{y}^\\gamma \\log(1 - \\hat{y})$$\n",
    "\n",
    "where:\n",
    "- $y$ is the ground truth label (0 or 1)\n",
    "- $\\hat{y}$ is the predicted probability\n",
    "- $\\alpha$ is the balancing factor (default: 0.25)\n",
    "- $\\gamma$ is the focusing parameter (default: 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modulating factor $(1 - \\hat{y})^\\gamma$ down-weights the loss for well-classified examples. For misclassified or difficult examples, this factor approaches $1$, meaning their loss is amplified. This allows the model to focus more on hard-to-classify examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "If the true label is $y = 1$ and the predicted probability is $\\hat{y} = 0.1$, the moduling factor is $(1 - 0.1)^\\gamma = 0.9^\\gamma$. For a large value $\\gamma$,The loss will focus heavily on this example because itâ€™s hard to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pros and Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros:\n",
    "- Excellent for class-imbalanced datasets where most examples are easy to classify, and only a few are hard.\n",
    "- Helps improve model performance in tasks like object detection and rare event classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cons:\n",
    "- Requires careful tuning of the focusing parameter $\\gamma$ and balancing factor $\\alpha$.\n",
    "- Can complicate training by focusing too much on hard examples, possibly leading to overfitting."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
