{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov-accelerated Adaptive Moment Estimation (Nadam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadam enhances the Adam optimizer by incorporating Nesterov momentum, which introduces a lookahead capability to gradient updates. This adjustment not only speeds up the convergence process but also improves the accuracy of the steps toward… \n",
    "\n",
    "The algorithm was described in the 2016 paper by Timothy Dozat titled “Incorporating Nesterov Momentum into Adam.” Although a version of the paper was written up in 2015 as a Stanford project report with the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to the mathematical formulation of the Nadam optimizer:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_t & = \\beta_1 v_{t-1} + (1 - \\beta_1) g_t \\\\\n",
    "\\bar{v}_t & = \\frac{(\\beta_1 v_t) + (1 - \\beta_1) \\nabla_{\\theta} J(\\theta_{t - 1})}{1 - \\beta_1^t} \\\\\n",
    "s_t & = \\beta_2 s_{t-1} + (1 - \\beta_2) g_t^2 \\\\\n",
    "\\bar{s}_t & = \\frac{s_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_t & = \\theta_{t-1} - \\alpha \\frac{\\bar{v}_t}{\\sqrt{\\bar{s}_t} + \\epsilon} \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so here's the end of Adam variant. You will see that most of the variant will be the combination of Original Adam and some other with a few tricky update."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
