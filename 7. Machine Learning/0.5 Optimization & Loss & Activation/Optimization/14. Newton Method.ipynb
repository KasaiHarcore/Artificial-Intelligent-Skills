{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GD methods I have presented are also called first-order methods, because the solution is based on the first derivative of the function. Newton's method is a second-order method, meaning the solution requires taking into account the second derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, up to this point, we have always solved the derivative of the loss function equal to zero to find local minimun points. (And in many cases, we have treated the resulting solution as a solution to the problem of finding the minimum value of the loss function.) There is a famous algorithm for solving the $f(x) = 0$ problem, called Newtonâ€™s method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method for $f(x) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![newton](./img/NewtonIteration_Ani.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of solving $f(x) = 0$ using Newton's method is as follows. Starting from an initial point $x_0$, which is close to the solution $x^*$, the tangent line (or tangent plane in higher dimensions) to the graph $y = f(x)$ at $x_0$ is constructed. The intersection point $x_1$ of this tangent line with the $x$-axis is taken as a better approximation of the solution $x^*$. The algorithm iteratively updates the point $x_1$, and this process continues until $f(x_t) \\approx 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This geometric interpretation of Newton's method leads to a formula that can be iterated. The equation of the tangent line at $x_t$ is:\n",
    "\n",
    "$$\n",
    "y = f'(x_t)(x - x_t) + f(x_t)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection of this tangent line with the $x$-axis can be found by solving for $x$ where $y = 0$. This yields the formula:\n",
    "\n",
    "$$\n",
    "x = x_t - \\frac{f(x_t)}{f'(x_t)} \\triangleq x_{t+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method for Finding Local Minima\n",
    "\n",
    "Applying this method to solve $f'(x) = 0$, we have:\n",
    "\n",
    "$$\n",
    "x_{t+1} = x_t - \\left(f''(x_t)\\right)^{-1} f'(x_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In higher dimensions, where $\\theta$ is a vector, the update rule becomes:\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\mathbf{H}(J(\\theta))^{-1} \\nabla_\\theta J(\\theta)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{H}(J(\\theta))$ is derivative in second order of $J(\\theta)$, called the Hessian matrix. This equation is a matrix if $\\theta$ is a vector. And $\\mathbf{H}(J(\\theta))^{-1}$ is the inverse of the Hessian matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited of Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The initial point $x_0$ must be close to the solution $x^*$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
