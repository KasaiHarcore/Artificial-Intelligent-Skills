{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Pattern\n",
    "\n",
    "Prompt Pattern is a way to record a structure of phrases and statements to solve a specific problem in a large language model. In many cases, an idea can be rewritten and expressed in arbitrary ways based on the needs and experiences of the user. However, the main ideas to be communicated are presented as a series of simple but basic statements.\n",
    "\n",
    "Example: Helpful Assistant Pattern\n",
    "\n",
    "Let's imagine that we want to record a new pattern to prevent an AI assistant from producing negative outcomes for the user. Let's call this pattern the \"Helpful Assistant\" pattern.\n",
    "\n",
    "Next, let's talk about the basic contextual statements that we need to include in the prompt for this pattern. Basic contextual statements:\n",
    "\n",
    "- You are a helpful AI assistant.\n",
    "\n",
    "- You will answer my questions or follow my instructions whenever you can.\n",
    "\n",
    "- You will never answer my questions in a derogatory, insulting, or hostile tone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at some examples that include each of these basic context statements, but may be worded or adapted differently\n",
    "\n",
    "For example:\n",
    "- You are an extremely skilled AI assistant who can provide the best possible answers to my questions. You will do your best to follow my instructions and only refuse to do what I ask when you have absolutely no other choice. You are dedicated to protecting me from harmful content and will never post anything offensive or inappropriate.\n",
    "\n",
    "Each example roughly follows the pattern but rephrases the basic context statements in a unique way. However, each example of the pattern will likely solve the problem of getting the AI ​​to try to act in a helpful way and not post inappropriate content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Persona Pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persona Prompt is a powerful method for using large language models to mine specific behaviors. It involves making the AI ​​imagine itself as a specific expert or entity that a person would typically consult for a specific outcome, and then instructing the model to act as that individual to generate a response. This allows the user to access different perspectives without the model needing to know the exact format or content in advance. By providing a prompt like “act like a smart person in a field,” we can trigger sharp and detailed responses from the model that match the assigned persona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It simplifies the process of interacting with large language models by combining complex instructions and expectations into a concise statement.\n",
    "- This approach not only facilitates the exploration of different perspectives and roles, but also maximizes the efficiency of requests by providing a comprehensive framework for generating diverse responses.\n",
    "- allows users to generate specific response types appropriate to different scenarios or requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This flexibility allows users to gather different perspectives and information from the model, increasing the breadth and depth of the responses generated.\n",
    "\n",
    "Additionally, it can be used as a means to enhance interactions with large language models by defining context and guiding the model's output towards the desired outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this pattern, your prompt should provide the following basic context commands:\n",
    "\n",
    "- Play as Persona X\n",
    "- Perform task Y\n",
    "We'll need to replace \"X\" with an appropriate persona, such as \"speech-language pathologist\" or \"dietitian\". You'll then need to specify the task for that persona to perform.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Act as a speech-language pathologist. Give an assessment of a three-year-old based on the speech sample \"I meed way woy\".\n",
    "\n",
    "- Act as a computer that is the victim of a cyberattack. Respond to any input I make with the output that the Linux terminal will produce. Ask me for the first command.\n",
    "\n",
    "- Act as a gourmet chef, I'll tell you what I'm eating and you'll tell me about my dietary choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing New Information to the Large Language Model\n",
    "\n",
    "While Prompting, it is important to provide the large language model with information that it does not have access to. Large language models are trained up to a point in time, but they may not know what happened after that point in time and may not have access to the data sources that we want to use. If we have our own documents and databases, we can use prompting to introduce new information to the model.\n",
    "\n",
    "**Always give the model enough information** to make the right decision. It cannot see what is around us or the context. It is important to provide enough information to make a reasonable decision, such as hidden assumptions, game rules or special things. These can be not only data but also rules built into the way your organization works or lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Size Limitation\n",
    "\n",
    "Prompts are inputs that a user has into a large language model, and there is a limit to the size of prompts that can be generated.\n",
    "\n",
    "Every large language model has a fundamental limit to the amount of information that can be fed into and sent to it. This has implications for thinking about rapid design.\n",
    "\n",
    "For example, when a user pastes a large amount of text related to the French Revolution into ChatGPT, ChatGTP responds with a message that the message is too long, indicating that the user cannot provide unlimited information at once.\n",
    "\n",
    "To introduce new information that ChatGPT or another large language model is not trained on, the user must be aware of the limit to the amount of information they can provide to the model at once. The user should try to select and use only the information they need to perform the task they are asking ChatGPT to perform. This involves being a content editor and having a context for the information.\n",
    "\n",
    "However, this only works if the way the summarization or filtering is done retains the information necessary for the task. As large language models get larger, they can reach sizes that are incompatible with many real-world tasks, especially when users interact directly with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Prompt\n",
    "\n",
    "Prompt là những quy tắc thiết yếu có thể lập trình các mô hình ngôn ngữ lớn để thực hiện các tác vụ một cách tự động. Chúng có thể bị ẩn khỏi người dùng và được sử dụng trong nhiều công cụ khác nhau, chẳng hạn như ChatGPT. Những lời nhắc gốc này xác định các quy tắc cơ bản cho sự tương tác của mô hình với người dùng, đảm bảo mô hình không nói bất kỳ điều gì xúc phạm hoặc gợi ý các hành động không phù hợp. Ví dụ: trợ lý cá nhân có thể ưu tiên đưa ra các đề xuất tiết kiệm thời gian để tiết kiệm thời gian.\n",
    "\n",
    "Tuy nhiên, có những người cố gắng tạo lời nhắc sẽ ghi đè lên những lời nhắc và câu lệnh này. Họ cố gắng đánh lừa công cụ này để tiết lộ dấu nhắc gốc hoặc bỏ qua nó. Việc xây dựng các công cụ xung quanh các mô hình ngôn ngữ lớn đòi hỏi phải biết cách tạo lời nhắc gốc sẽ ảnh hưởng đến các cuộc hội thoại tiếp theo. \n",
    "\n",
    "Root Prompt giống như seed cho cuộc trò chuyện, cung cấp các quy tắc phải tuân theo. Nó có thể được sử dụng để lập trình trải nghiệm tùy chỉnh xung quanh mô hình và đặt các thanh chắn bảo vệ để đảm bảo hành vi xấu không được tạo ra. \n",
    "\n",
    "Ví dụ: nếu ChatGPT cho biết hoạt động đào tạo của họ đã dừng vào năm 2019, thì nó có thể đặt lại ngày có thể trả lời các câu hỏi trước đó. Điều này có thể được thực hiện bằng cách sử dụng các mẫu lời nhắc khác nhau, chẳng hạn như cho biết rằng dữ liệu đào tạo của ChatGPT chỉ tính đến năm 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Refinement Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QRP is a simple way to improve interactions with large language models like GPT chat. It involves looking at the GPT chat or another large language model whenever a question is asked to try to improve it.\n",
    "\n",
    "It involves looking at another large language model whenever a question is asked to try to improve it. Because it has more information and underlying thinking behind its questions than a human.\n",
    "\n",
    "Whenever a question is asked, the model suggests a better question and asks if the user would like to use it instead. This is useful from a user experience perspective because it allows the model to generate better questions without requiring the user to cut and paste the question. Instead, it asks the user if they would like to use the suggested question instead.\n",
    "\n",
    "For example, if a user asks a general question like “should I go to Vanderbilt University?”, chatGPT suggests suggested questions that consider factors that should be considered when deciding whether or not to attend Vanderbilt University and how they fit into their personal goals and priorities. This helps the user identify missing information and make a more informed decision.\n",
    "\n",
    "Usually we will see it in the form of LLM asking the user for more information to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this pattern, your request should make the following basic context statements:\n",
    "- From now on, whenever I ask a question, suggest a better version of the question to use instead (or tell me if I want to use a better version)\n",
    "\n",
    "Example:\n",
    "- From now on, whenever I ask a question, suggest a better version of the question to use instead\n",
    "- From now on, whenever I ask a question, suggest a better version of the question and ask me if I want to use it instead\n",
    "\n",
    "Example Customization:\n",
    "- Whenever I ask a question about dieting, suggest a better version of the question that emphasizes healthy eating habits and healthy nutrition. Ask me the first question to refine.\n",
    "- Whenever I ask a question about who is the greatest of all time (GOAT), suggest a better version of the question that puts multiple players unique achievements in perspective. Ask me the first question to refine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cognitive Verifier Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs can often reason better if a question is broken down into additional questions that provide answers that combine to form an overall answer to the original question. The purpose of the model is to force LLMs to always break down questions into a set of questions that can be used to better answer the original question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:\n",
    "- When you are asked a question, follow these rules:\n",
    "- Create additional questions that help answer the question more precisely\n",
    "- Combine answers to individual questions to create the final question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customization examples:\n",
    "- When asked to create a recipe, follow these rules. Create some additional questions about the ingredients I have on hand and the cooking equipment I own. Combine the answers to these questions to help create a recipe that I have the ingredients and tools to make.\n",
    "- When asked to plan a trip, follow these rules. Create some additional questions about my budget, preferred activities, and whether I will have a car. Combine the answers to these questions to better plan my trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audience Persona Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a tool that allows large language models to provide rich information about their actions and outcomes. It involves adding an audience persona model, which tells the model to create a product for a specific persona. This allows the model to customize its product to the needs and preferences of the audience.\n",
    "\n",
    "An example of using the audience persona template includes explaining large language models to someone with no background in computer science. The model describes itself as a virtual writer who can understand and generate human language, making it accessible and relatable to anyone. Language models are used in various applications such as speech recognition, machine translation, and chatbots.\n",
    "\n",
    "Another example is given to a bored second grader. The model describes a large language model as a robot friend who can complete sentences, ask questions, and even tell stories. The robot friend's reading time is used to complete sentences, ask questions, and answer questions, making it a useful tool for understanding and engaging with the audience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, your request should make the following basic context statements:\n",
    "\n",
    "- Explain to me X.\n",
    "\n",
    "- Suppose I am Persona Y.\n",
    "\n",
    "Replace “Y” with an appropriate persona, such as “with a limited background in computer science” or “a healthcare professional”. You will then need to identify the topic X that needs to be explained.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Explain to me the big language models. Suppose I am a bird.\n",
    "\n",
    "- Explain to me how the supply chain of American grocery stores works. Suppose I am Ghengis Khan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flipping Interaction Pattern\n",
    "\n",
    "It is a useful tool for large language models to ask questions and provide answers to guide problem solving or achieve a desired outcome. This approach involves inverting the interaction between a user asking a question and a large language model providing answers. This can be used in a variety of ways, such as playing a game or achieving a goal.\n",
    "\n",
    "An example of this model is asking a large language model questions about a specific topic, such as fitness goals. The model should ask questions until it has enough information to recommend a strength training regimen. The more information provided, the better the model can ask.\n",
    "\n",
    "The flipped interaction model also allows the model to take into account answers from previous questions, such as the type of exercise recommended for a particular problem. The model will generate an entire weight training regimen based on the information provided.\n",
    "\n",
    "Some users may encounter additional questions or general initial planning when asking questions to a large language model, but this is usually not a major issue. By providing the model with the necessary information and context, the model can effectively guide the problem solving process and achieve the desired result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this model, your request should make the following basic context statements:\n",
    "- I want you to ask me questions to achieve X.\n",
    "- You should ask questions until condition Y is met or until this goal is achieved (alternatively, forever).\n",
    "- (Optional) ask me once, twice, ask me the first question, etc.\n",
    "\n",
    "Replace “X” with an appropriate goal, such as “create a meal plan” or “create variations of my marketing materials.” You should specify when to stop asking questions with Y.\n",
    "\n",
    "For example:\n",
    "- I want you to ask me questions to help me create variations of my marketing materials. You should ask questions until you have enough information about my current message draft, audience, and goals. Ask me the first question.\n",
    "\n",
    "- I want you to ask me questions to help me diagnose a problem with my Internet. Ask me questions until you have enough information to identify 2 possible causes. Ask me one question at a time. Ask me the first question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Pattern II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gameplay Pattern\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "It is a game where a large language model (LLM) acts as the game controller and gives you prompts to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Game Model:**\n",
    "- Objective: Improve your technical skills quickly in a fun and engaging way.\n",
    "- Setup:\n",
    "- You tell LLM the topic of the prompt you want to create.\n",
    "- You can optionally specify additional information such as the desired prompt template.\n",
    "- How to Play:\n",
    "- LLM gives you a task that can be solved through the prompt.\n",
    "- The task involves a specific output format.\n",
    "- You write a prompt to solve the task.\n",
    "- LLM executes your prompt and tells you how well it achieves the desired result.\n",
    "- LLM may ask clarifying questions throughout the process.\n",
    "- Learning:\n",
    "- You can test your understanding of technical concepts quickly.\n",
    "- LLM provides feedback on your prompt, including identifying errors.\n",
    "\n",
    "**Benefits**\n",
    "- Engaging Practice: Makes learning a technique quickly more interactive and fun.\n",
    "- Personalized Learning: LLM tailors tasks to your chosen topic and desired prompt patterns.\n",
    "- Feedback and Guidance: LLM helps you identify areas for improvement in your prompts.\n",
    "- Content Generation: LLM generates new and exciting tasks for you to tackle.\n",
    "\n",
    "**Example Playthrough:**\n",
    "\n",
    "- The text describes an example where the user practices creating prompts for different tasks:\n",
    "- Check for duplicates in a list.\n",
    "- Count the number of words in a sentence.\n",
    "- Identify leap years.\n",
    "- Identify palindromes\n",
    "- Assemble a bookshelf using a recipe-like prompt.\n",
    "- The user also demonstrates how to change the theme of the prompt by introducing prompt patterns such as context managers and sample templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is it?**\n",
    "\n",
    "It is a technique you can use with large language models (LLMs) to control the format of the output you receive.\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "- Allows you to specify a template for the LLM's output, including placeholders for the content you want it to generate.\n",
    "\n",
    "- Ensures the LLM follows your formatting instructions and inserts the generated content into the specified locations.\n",
    "\n",
    "**How ​​it works:**\n",
    "- Define your template: Creates a template in plain text with uppercase words that represent placeholders for the LLM's output.\n",
    "\n",
    "- Explain the placeholders: Describes to the LLM what type of content will be inserted for each placeholder. This can be a simple combination or include instructions and constraints.\n",
    "\n",
    "- Provide data: Provides the LLM with the information needed to generate the content for the placeholders.\n",
    "- Get formatted output: LLM will fill the generated content into the placeholders in your template according to your specifications.\n",
    "\n",
    "Template: QUESTION* * *question* * * *ANSWER* * *answer* * * (Asterisks are used for bold and italics in Markdown formatting)\n",
    "\n",
    "Placeholder: QUESTION (not capitalized) - This part remains in the output. question (capitalized) - This is where LLM generates the question based on the data provided.\n",
    "\n",
    "Answer (not capitalized) - This part remains in the output.\n",
    "answer (capitalized) - This is where LLM generates the answer to the question.\n",
    "\n",
    "**Benefits of Template Pattern:**\n",
    "- Efficiency: Saves time by eliminating the need to manually write out the entire formatted output.\n",
    "\n",
    "Accuracy: Ensures LLM follows your format and reduces the risk of errors.\n",
    "- Flexibility: Placeholders can be simple or complex, allowing for sophisticated control over the content and structure of the output.\n",
    "\n",
    "By using Templates, you can get the information you need from large language models in the exact format you want, making them more efficient and useful tools for your specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "- Create a random strength workout for me today with additional exercises. I will provide a template for your product. The QUANTUMED WORD is my placeholder for the content. Try to incorporate the output into one or more of the locations I list. Please keep the overall format and template I provide. Here is the template: NAME, REPS @ SETS, MUSCLE GROUPS WORKED, DIFFICULTY SCALE 1-5, FORM NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Please create a grocery list for me to make macaroni and cheese from scratch, garlic bread, and marinara sauce from scratch. I will provide a template for your product. <placeholder> is my placeholder for the content. Try to combine the output into one or more of the locations I list. Please keep the overall format and template I provide. Here is the template: ```Aisle <name of hall>: <item needed from hall>, <qty> (<dish(es) used in>)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Language Creation Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is it?**\n",
    "\n",
    "It is a technique used with large language models (LLMs) to create custom communication with them. This custom communication can be in the form of shorthand, abbreviations, or even entirely new symbols.\n",
    "\n",
    "**Why use it?**\n",
    "\n",
    "There are several benefits to using Meta Language Generation Templates:\n",
    "\n",
    "- Efficiency: It allows you to communicate complex information to an LLM in a concise manner, saving time and effort compared to writing everything out in full sentences.\n",
    "\n",
    "- Accuracy: By defining the meaning of your shorthand, you can ensure that the LLM interprets your instructions exactly as intended, potentially reducing ambiguity.\n",
    "\n",
    "- Consistency: A shared shorthand across a team or organization can lead to more consistent reasoning and data entry from the LLM.\n",
    "\n",
    "**How ​​does it work?**\n",
    "- Define your language: Decide what symbols, abbreviations, or signs you want to use in your communication with the LLM.\n",
    "- Teach the LLM: Give the LLM examples of your new language and explain what they mean in plain English. This is similar to providing “a few examples” for other LLM tasks.\n",
    "- Use your language: Once the LLM understands your shorthand, you can use it to communicate and get results.\n",
    "\n",
    "Example: Trip Planning App\n",
    "\n",
    "The conversation describes a scenario where the Metalanguage Generation Template is used to create shorthand for trip planning. Locations and durations are represented by city names, commas, numbers, and arrows. This allows for defining a trip much faster than writing everything out in full sentences.\n",
    "\n",
    "***Key Points to Remember:***\n",
    "- Your LLM needs to be clearly taught your new language through examples and explanations.\n",
    "- Your shorthand must be clear and unambiguous to avoid confusion.\n",
    "- This template can be applied to a variety of tasks beyond trip planning, allowing for effective communication with LLMs in any field.\n",
    "\n",
    "By using the Meta Language Generation Template, you can unlock new ways to interact with large language models, making them more efficient and powerful tools for your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this pattern, your prompt must provide the following basic context statements:\n",
    "\n",
    "- When I say X, I mean Y (or want you to do Y)\n",
    "\n",
    "Replace \"X\" with a suitable sentence, symbol, word, etc. You will then need to convert this word to its meaning, Y.\n",
    "\n",
    "For example:\n",
    "\n",
    "When I say `\"variations(<something>)\"`, I mean give me ten different variations of `<something>`\n",
    "\n",
    "Usage: \"variations(company names for a company that sells software services for prompt engineering)\"\n",
    "\n",
    "Usage: \"variations(a marketing slogan for pickles)\"\n",
    "\n",
    "When I say Task X [Task Y], I mean Task X depends on Task Y being completed first.\n",
    "\n",
    "Usage: \"Describe the steps for building a house using my task dependency language.\"\n",
    "\n",
    "Usage: \"Provide an ordering for the steps: Boil Water [Turn on Stove], Cook Pasta [Boil Water], Make Marinara [Turn on Stove], Turn on Stove [Go Into Kitchen]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example prompt:\n",
    "\n",
    "We are going to create a trip planning application. I will describe my trip and you will list interesting things to do in places that I will pass through. I will tell you how many days I will stay in each place and you will list possible itineraries.\n",
    "\n",
    "To describe my route, I am going to use a shorthand notation.\n",
    "\n",
    "When I say \"Nashville,3 -> Memphis,2\", I mean that my route will go from Nashville to Memphis and that I will stay 3 days in Nashville and 2 days in Memphis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipt Pattern\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "It is a technique you can use with large language models (LLMs) to help them complete a sequence of steps to achieve a goal.\n",
    "\n",
    "**What it does:**\n",
    "- Helps you fill in the missing steps in a process.\n",
    "\n",
    "- Takes your incomplete instructions and creates a complete set of steps.\n",
    "\n",
    "**How ​​to use it:**\n",
    "- Define your goal: Tell the LLM what you ultimately want to achieve.\n",
    "\n",
    "- Provide known steps: Give the LLM some steps that you know are involved in achieving the goal. You can use placeholders (like dots) to indicate missing steps.\n",
    "\n",
    "- Let the LLM fill in the gaps: The LLM will use its knowledge to create the missing steps and provide a complete set of instructions.\n",
    "\n",
    "Example 1: Trip planning\n",
    "- Goal: Create a trip itinerary from Nashville to Fairhope, Alabama with two stops in between.\n",
    "- Known steps: Start in Nashville, stop in Fairhope.\n",
    "- Placeholders: Use dots (...) to indicate where to stop.\n",
    "\n",
    "=> LLM will then generate a complete itinerary that includes the two missing stops, potentially suggesting locations like Birmingham and Montgomery, Alabama.\n",
    "\n",
    "Example 2: Road trip planning\n",
    "- Objective: Plan a trip from Los Angeles to New York with unknown stops.\n",
    "\n",
    "- Known steps: Start in Los Angeles, end in New York.\n",
    "\n",
    "- Placeholders: Use multiple dots (...) to indicate multiple unknown stops.\n",
    "\n",
    "=> LLM will generate a detailed itinerary with many different potential stops along the way, taking into account the long distances between the two cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this template, your prompt should provide the following basic context statements:\n",
    "- I want to achieve X\n",
    "- I know that I need to do steps A, B, C\n",
    "- Give me the complete sequence of steps\n",
    "- Fill in any missing steps\n",
    "- (Optional) Identify any unnecessary steps\n",
    "\n",
    "Replace “X” with an appropriate task. You will then need to specify the steps A, B, C that you know need to be part of the complete formula/plan.\n",
    "\n",
    "For example:\n",
    "- I want to buy a house. I know that I need to do the steps of making an offer and closing the home purchase. Give me the complete sequence of steps. Fill in any missing steps.\n",
    "- I want to drive to New York from Nashville. I know that I want to pass through Asheville, NC on the way and I don’t want to drive more than 300 miles each day. Give me the complete sequence of steps. Fill in any missing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Approaches Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is it?**\n",
    "\n",
    "It is a technique you can use with large language models (LLMs) to help them think of multiple solutions to a problem. Here is a breakdown of how it works:\n",
    "\n",
    "**What it does:**\n",
    "\n",
    "Helps you generate multiple creative approaches to solving a problem.\n",
    "\n",
    "Taking a single problem and expanding it to multiple potential solutions.\n",
    "\n",
    "**How ​​to use it:**\n",
    "\n",
    "- Framing your request: Tell the LLM what problem you want to solve.\n",
    "\n",
    "- Using templates: Use phrases like “list alternative approaches” or “suggest different approaches” to prompt the LLM.\n",
    "\n",
    "- Refine the scope (optional): You can specify the desired context or format of the solutions (e.g. “to solve this problem by learning several times”).\n",
    "\n",
    "- Evaluating and selecting: The LLM will provide multiple approaches. Analyze them and choose the one that best suits your needs.\n",
    "\n",
    "**Benefits:**\n",
    "- Expands your thinking: Exposes you to solutions you might not have considered on your own.\n",
    "\n",
    "- Improves problem solving: Helps you think creatively and strategically when tackling challenges.\n",
    "\n",
    "Provides comparisons: LLMs can sometimes compare the pros and cons of different approaches, making decision making easier.\n",
    "\n",
    "Example 1: Write a prompt to determine leap years\n",
    "\n",
    "Problem: Write a statement to determine leap years.\n",
    "- Alternative approaches:\n",
    "\n",
    "- Approach 1: Direct question format (e.g., \"Is this a leap year?\")\n",
    "\n",
    "- Approach 2: Conversation format (e.g., \"Hey, can you tell me if this is a leap year?\")\n",
    "\n",
    "Example 2: Summarizing email threads\n",
    "\n",
    "Problem: Write a prompt to automatically summarize questions and comments from an email thread.\n",
    "\n",
    "- Alternative approaches:\n",
    "\n",
    "- Approach 1: Identify the question, then summarize the corresponding responses.\n",
    "\n",
    "- Approach 2: Simulate a conversation where the LLM acts as the summarizer.\n",
    "\n",
    "- Approach 3: Treat the email thread as a case study and provide a summary report.\n",
    "\n",
    "Additional tips:\n",
    "- You can adjust the sample wording based on your specific needs (e.g., \"list creative solutions\" or \"suggest unconventional approaches\").\n",
    "\n",
    "- Don't blindly accept LLM's suggestions. Evaluate them critically and make sure they fit your problem and goals.\n",
    "- They can be used to generate additional ideas or improve existing solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this template, your prompt should provide the following basic contextual statements:\n",
    "- If there are other ways to complete the task X I gave you, list the best alternative methods\n",
    "- (Optional) compare/contrast the pros and cons of each method\n",
    "- (Optional) include the original way I asked\n",
    "- (Optional) remind me of the method I want to use\n",
    "\n",
    "Replace \"X\" with an appropriate task.\n",
    "\n",
    "For example:\n",
    "- For each prompt I give you, If there are other ways to phrase the prompt I gave you, list the best alternative ways to phrase it. Compare/contrast the pros and cons of each way to phrase it.\n",
    "- For anything I ask you to write, identify the basic problem I'm trying to solve and how I'm trying to solve it. List at least one alternative approach to solving the problem and compare/contrast that approach with the original approach I asked you to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Prompt:\n",
    "\n",
    "From now on, if there are alternative ways to accomplish the same thing, list the best alternate approaches. Compare and contrast the alternatives and ask me which one I prefer.\n",
    "\n",
    "Write a prompt for ChatGPT using few shot examples to determine if a date in YYYY-MM-DD format is a leap year. The output should either be \"YYYY is a leap year\" or \"This is not a leap year\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask for Input Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "\n",
    "Whenever I ask you to write a prompt for me to accomplish a task, list what the task is, list alternative approaches for completing task, and then write a prompt for yourself for each approach. When you are done, ask me for the next prompt to create alternatives for."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
