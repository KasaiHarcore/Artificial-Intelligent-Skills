{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API: *ls__5179d3562f654bd2b1ff768e646bacaa* : Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nguye\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\nguye\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting pretty_errors\n",
      "  Using cached pretty_errors-1.2.25-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: IPython in c:\\users\\nguye\\anaconda3\\lib\\site-packages (8.20.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\nguye\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\nguye\\anaconda3\\lib\\site-packages (0.0.38)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\nguye\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\nguye\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from pretty_errors) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from IPython) (5.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (0.1.63)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.6)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.40.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: executing in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from stack-data->IPython) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from stack-data->IPython) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nguye\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/290.4 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 81.9/290.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 225.3/290.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.4/2.1 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 10.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf, pretty_errors, langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-community-0.2.1 pretty_errors-1.2.25 pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas pretty_errors pypdf IPython langchain langchain-community langchain-core sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pprint import pprint\n",
    "import pretty_errors\n",
    "import pypdf\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter\n",
    ")\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader, \n",
    "    DirectoryLoader\n",
    ")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "# from langchain_community.llms import CTransformers # For cpu run\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "# from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r\"assets\\pdf\"\n",
    "vector_db_path = r\"assets\\vector_db\"\n",
    "# strg = input(\"Enter a string: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_text(strs):\n",
    "    \"\"\"\n",
    "    Create a vector database from the text\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the text splitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator = \"\\n\",\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 50,\n",
    "        length_function = len\n",
    "    )\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    chunks = text_splitter.split_text(strs)\n",
    "    \n",
    "    # Load the GPT-4 embeddings model\n",
    "    embeddings_model = GPT4AllEmbeddings(model_file = \"model/all-MiniLM-L12-v2.Q8_0.gguf\")\n",
    "    \n",
    "    # Create the vector database using FAISS\n",
    "    database = FAISS.from_text(chunks, embeddings_model)\n",
    "    database.save_local(vector_db_path)\n",
    "    \n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_pdf(path):\n",
    "    \"\"\"\n",
    "    Create a vector database from the documents of a PDF file.\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(path, glob = \"*.pdf\", loader_cls = PyPDFLoader, use_multithreading = True, show_progress = True)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1024,\n",
    "        chunk_overlap = 20,\n",
    "        length_function=len,\n",
    "        separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200B\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",],\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    embeddings_model = GPT4AllEmbeddings(model_file = \"model/all-MiniLM-L12-v2.Q8_0.gguf\")\n",
    "    \n",
    "    database = FAISS.from_documents(chunks, embeddings_model)\n",
    "    database.save_local(vector_db_path)\n",
    "\n",
    "    return database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(\n",
    "    model = \"llama2:13b\",\n",
    "    num_gpu = -1,\n",
    "    num_ctx = 4096,\n",
    "    temperature = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gen(template):\n",
    "    return PromptTemplate(\n",
    "        template = template,\n",
    "        max_tokens = 4096,\n",
    "        temperature = 0.01,\n",
    "        top_p = 0.95,\n",
    "        frequency_penalty = 0.0, \n",
    "        presence_penalty = 0.0, \n",
    "        stop_sequences = [\"\\n\"],\n",
    "        input_variables = [\"question\"],\n",
    "        return_only_outputs = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain_lang(pt, llm_model):\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm_model,\n",
    "    retriever = VectorStoreRetriever(vectorstore = create_db_from_pdf(pdf_path)),\n",
    "    memory = ConversationSummaryMemory(llm = llm_model),\n",
    "    chain_type_kwargs = {\"prompt\": pt, \"verbose\": True},\n",
    "    return_source_documents = False\n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"<|im_start|>system\\nSử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời.\\n\n",
    "    {context}<|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:00<00:00, 30.06s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_gen(template)\n",
    "chain = chain_lang(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Entering new StuffDocumentsChain chain...\n",
      "\n",
      "\n",
      "> Entering new LLMChain chain...\n",
      "Prompt after formatting:\n",
      "<|im_start|>system\n",
      "Sử dụng thông tin sau đây để trả lời câu hỏi. Nếu bạn không biết câu trả lời, hãy nói không biết, đừng cố tạo ra câu trả lời.\n",
      "\n",
      "    vey of current methods for constructing decision tree classiﬁers in a top-down\n",
      "manner. The chapter suggests a uniﬁed algorithmic framework for presenting\n",
      "thesealgorithmsanddescribesvarioussplittingcriteriaandpruningmethodolo-\n",
      "gies.\n",
      "Keywords: Decision tree, Information Gain, Gini Index, Gain Ratio, Pruning, Minimum\n",
      "Description Length, C4.5, CART,ObliviousDecision Trees\n",
      "1. Decision Trees\n",
      "A decision tree is a classiﬁer expressed as a recursive partition of the in-\n",
      "\n",
      "Chapter 9\n",
      "DECISION TREES\n",
      "Lior Rokach\n",
      "Department of Industrial Engineering\n",
      "Tel-AvivUniversity\n",
      "liorr@eng.tau.ac.il\n",
      "Oded Maimon\n",
      "Department of Industrial Engineering\n",
      "Tel-AvivUniversity\n",
      "maimon@eng.tau.ac.il\n",
      "Abstract DecisionTreesareconsideredtobeoneofthemostpopularapproachesforrep-\n",
      "resentingclassiﬁers. Researchersfromvariousdisciplinessuchasstatistics,ma-\n",
      "chinelearning,patternrecognition,andDataMininghavedealtwiththeissueof\n",
      "growingadecisiontreefromavailabledata. Thispaperpresentsanupdatedsur-\n",
      "\n",
      "Decisiontreesthemselvesareanexampleofdynamicstructure,becauseeach\n",
      "nodeinthetreedetermineswhichofitssubtreesshouldbeevaluatedforeachinput.\n",
      "Asimplewaytoaccomplishtheunionofdeeplearninganddynamicstructure\n",
      "4 4 9\n",
      "\n",
      "navigating them from the root of the tree down to a leaf, according to the\n",
      "outcome of the tests along the path. Figure 9.1 describes a decision tree that\n",
      "reasons whether or not a potential customer will respond to a direct mailing.\n",
      "Internal nodes are represented as circles, whereas leaves are denoted as tri-\n",
      "angles. Note that this decision tree incorporates both nominal and numeric at-\n",
      "tributes. Giventhisclassiﬁer,theanalystcanpredicttheresponseofapotential<|im_end|>\n",
      "<|im_start|>user\n",
      "Decision Tree có công thức như nào là gì?<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Finished chain.\n",
      "\n",
      "> Finished chain.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\"Decision Tree có công thức như nào là gì?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': '',\n",
      " 'query': 'Decision Tree có công thức như nào là gì?',\n",
      " 'result': ' A decision tree is a popular machine learning approach for '\n",
      "           'classifying data. It is a recursive partition of the input data, '\n",
      "           'where each internal node in the tree represents a test or query, '\n",
      "           'and each leaf node represents a class label or prediction. The '\n",
      "           'tree grows top-down, with each node determining which of its '\n",
      "           'subtrees should be evaluated for each input.\\n'\n",
      "           '\\n'\n",
      "           'There are several methods for constructing decision trees, '\n",
      "           'including:\\n'\n",
      "           '\\n'\n",
      "           '1. Information Gain: This method selects the best feature to split '\n",
      "           'the data based on the amount of information gained by doing so.\\n'\n",
      "           '2. Gini Index: This method selects the feature that leads to the '\n",
      "           'most even distribution of the data among the classes.\\n'\n",
      "           '3. Gain Ratio: This method selects the feature that results in the '\n",
      "           'largest gain ratio, which is the ratio of the reduction in '\n",
      "           'uncertainty about the class labels after splitting the data.\\n'\n",
      "           '4. Pruning: This method removes branches of the tree that do not '\n",
      "           'contribute much to the accuracy of the predictions.\\n'\n",
      "           '5. Minimum Description Length: This method selects the features '\n",
      "           'that result in the shortest description of the data.\\n'\n",
      "           '\\n'\n",
      "           'Decision trees can be used for both classification and regression '\n",
      "           'tasks, and they are often used as a baseline model to compare the '\n",
      "           'performance of more complex machine learning algorithms. Some '\n",
      "           'popular decision tree algorithms include C4.5, CART, and Oblivious '\n",
      "           'Decision Trees.\\n'\n",
      "           '\\n'\n",
      "           'In summary, decision trees are a simple yet powerful machine '\n",
      "           'learning approach for classifying data. They work by recursively '\n",
      "           'partitioning the input data into smaller subsets based on the '\n",
      "           'values of the features, and each leaf node represents a class '\n",
      "           'label or prediction. There are several methods for constructing '\n",
      "           'decision trees, including information gain, Gini index, gain '\n",
      "           'ratio, pruning, and minimum description length.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
