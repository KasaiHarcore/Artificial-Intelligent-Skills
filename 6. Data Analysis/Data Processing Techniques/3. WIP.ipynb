{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries that support machine learning mostly only accept input data in numeric form. However, we have seen that with tabular data, very often data fields are stored as categories. Even many data fields are stored in numeric format but are still considered categories. For example, the user ID can be any value, as long as it is not duplicated. They can be numeric values ​​1, 2, 3, … but these values ​​should not be included directly in the model.\n",
    "\n",
    "One thing that needs to be emphasized is that a good machine learning model is one that returns close output results when the input data (in numerical form) is close to each other. User codes, product codes, or any other type of code that is numbered in random order cannot be considered highly similar when the two codes are close to each other. Even if the codes are intentionally typed, they are only close to each other in one-dimensional space. Information can be defined as being “close to each other” in a higher dimensional space. As another example, let's say the days of the week are numbered 1 (Sunday), (Monday) 2, ..., (Monday) 7; Days 1 and 2 are close to each other, but days 1 and 7 are closer because they are the same weekend. Placing dates as points on a circle in two-dimensional space can yield more value because 1 is close to both 7 and 2.\n",
    "\n",
    "Thus, with category data, we not only need to put them into digital form so that algorithms can process them, but we also need to put them into reasonable values ​​in multi-dimensional space to bring about good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "\n",
    "The most traditional way to convert item data into digital form is one-hot encoding. In this encoding, a \"dictionary\" needs to be built containing all possible values ​​of each data category. Each item value will then be encoded by a binary vector with all elements equal to 0 except one element equal to 1 corresponding to the position of that item value in the dictionary.\n",
    "\n",
    "For example, if we have one-column data as \"New York\", \"California\", \"Los Angeles\", we do the following steps:\n",
    "- Build a dictionary. In this case, we can build a dictionary as [\"New York\", \"California\", \"Los Angeles\"].\n",
    "- After building the dictionary, we need to save the index of each item in the dictionary. With the dictionary as above, the corresponding index is [0, 1, 2].\n",
    "- Finally, we encode the original values ​​as follows:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Original value</th>\n",
    "        <th>Encoded value</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>New York</td>\n",
    "        <td>[1, 0, 0]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>California</td>\n",
    "        <td>[0, 1, 0]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Los Angeles</td>\n",
    "        <td>[0, 0, 1]</td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each item value is encoded in a vector with only one element equal to 1 at its corresponding position in the dictionary, this vector is called a “one-hot vector”. The dimension of this vector is exactly equal to the number of words in the dictionary. Interpreted in another way, each binary value in this vector represents whether the item value under consideration \"is\" the corresponding value in the dictionary. For new values ​​that are not in the dictionary (out-of-vocabolary or OOV), we can encode them as [0, 0, 0] in the sense that they are not any values ​​in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common way to encode values ​​that are not in the dictionary is to add the word \"unknown\" to the dictionary and all new values ​​are placed in this \"unknown\" category. It is important to note that \"unknown\" is also a possible value in the data set. Encoding unknown values ​​with the same vector can confuse the model that these are two same values. If somehow you know these values ​​will appear a lot in the future, you should specifically include them in the dictionary to have your own encoding, avoiding overlap with other values. If these values ​​rarely occur, we can put them together in one code and consider them to have the same nature as \"rare\". Trying to encode for each rare value will result in having to use a lot of memory and the model will also be more complicated to try to learn unique cases, in which case overfitting can easily occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>population (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  population (M)\n",
       "0     New York             7.0\n",
       "1   California             9.0\n",
       "2  Los Angeles             0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_train = pd.DataFrame(\n",
    "    data={\"location\": [\"New York\", \"California\", \"Los Angeles\"], \"population (M)\": [7, 9, 0.5]} # Example numbers\n",
    ")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply one-hot encryption to the \"location\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "  (0, 2)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder()\n",
    "\n",
    "onehot_encoded_location = onehot.fit_transform(df_train[[\"location\"]])\n",
    "print(type(onehot_encoded_location))\n",
    "print(onehot_encoded_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few points to note here. First, the default \"onehot_encoded_location\" return result is stored in the <code>scipy.sparse.csr.csr_matrix</code> type, which is a special type for storing two-dimensional arrays with a majority of zero elements. This way of saving is very convenient in terms of storage. Remember in this case because each vector has only one non-zero element. If the dictionary size increases to millions and we store the matrix in normal form, it will be a waste of resources to store so many values. 0 doesn't carry much information.\n",
    "\n",
    "When printing \"onehot_encoded_location\", we will see the column. The first column is the coordinates of the non-zero points, the second column is the value of the element at that coordinate – always equal to 1 in this case.\n",
    "\n",
    "To return the result in regular matrix form, we can add <code>sparse = False</code> when initializing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(sparse=False)\n",
    "\n",
    "onehot_encoded_location = onehot.fit_transform(df_train[[\"location\"]])\n",
    "print(onehot_encoded_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['California', 'Los Angeles', 'New York'], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to save this order for consistency when encoding data later.\n",
    "\n",
    "For values ​​not in the dictionary, sklearn provides two ways to handle them via the handle_unknown variable (see the official documentation for more details). This variable can take on one of two values ​​'error' (default) or 'ignore'. With 'error', the program will stop running and report an error when encountering a value that is not in the dictionary. With 'ignore', this encoder will transform strange values ​​into a vector of all 0. Unfortunately, this encoder does not support the case of lumping new values ​​into a separate category. The use of 'error' and 'ignore' depends on the context. If you know for sure all possible values ​​of that item data, you should use 'error' to catch erroneous input cases. Otherwise, you should use 'ignore'; However, be careful with misspellings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing\n",
    "\n",
    "One-hot encoding has a major limitation: it is necessary to know the dictionary and its size in advance. This dictionary should also be saved for coding new categories in the future. Imagine an e-commerce store has 1000 items today but in a month from now, that store has 1000 new items. So how should those new items be encoded? Obviously encoding them with a zero vector or with a one-hot vector corresponding to \"unknown\" will reduce model quality because there is no clear distinction between the 1000 new items. At this point, to be able to continue using one-hot encryption, we need to update the dictionary and re-encode all category values. This means that the model's input will change and there is a high possibility that we will also need to change the model's architecture to adapt to the change in input size.\n",
    "\n",
    "A technique used a lot to solve this problem is hashing. Hashing is a transformation of any input value into an integer. A good hash function is one that has the property of turning different input values ​​into evenly distributed points within the range of possible values ​​(32-bit integers or more depending on the hash function). Another characteristic is that different input values ​​will be transformed into integers with different high probability, especially when using a large number of bits.\n",
    "\n",
    "To use hashing as a way to transform category values ​​to a natural number used in machine learning models, we can perform the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert item values ​​to string format (some hash functions only accept string input).\n",
    "\n",
    "- Choose a \"deterministic\" hash function, that is, a function that always returns a fixed number in all runs if the input remains unchanged. This is very important because if for a value the hash function returns different outputs, the machine learning model cannot know that the inputs are the same. Note that some hash functions are capable of returning different values, possibly for security reasons, we need to avoid using these hash functions.\n",
    "\n",
    "- Estimate the number of different elements of the category data and then choose a natural number $K$ as the mod. Take the remainder of the result in step two when divided by this number $K$ as the index for the corresponding category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Predict Future Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 22170\n",
      "Number of category: 84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!ABBYY FineReader 12 Professional Edition Full...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***В ЛУЧАХ СЛАВЫ   (UNV)                    D</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>***ГОЛУБАЯ ВОЛНА  (Univ)                      D</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***КОРОБКА (СТЕКЛО)                       D</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           item_name  item_id  \\\n",
       "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
       "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
       "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
       "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
       "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
       "\n",
       "   item_category_id  \n",
       "0                40  \n",
       "1                76  \n",
       "2                40  \n",
       "3                40  \n",
       "4                40  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales_path = \"https://media.githubusercontent.com/media/tiepvupsu/tabml_data/master/sales/\"\n",
    "df_items = pd.read_csv(sales_path + \"items.csv\")\n",
    "print(f\"Number of items: {len(df_items)}\")\n",
    "print(f\"Number of category: {len(df_items['item_category_id'].unique())}\")\n",
    "df_items.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are 22,170 different products divided into 84 different categories. These items can be directly used to construct one-hot vectors. We can also see that there will be many products divided into the same category. If there are no other characteristics to differentiate the products, we will build a model where all products in the same category have the same properties. To be able to separate products, we can process additional information about product names in the first column. This will be relatively difficult because not all engineers know Russian. Another way is to use <code>item_id</code> as the category characteristic and build a one-hot vector for this column with 22170 elements. This is a relatively large number of elements. In addition, in the training data (\"sales_train.csv\" file), many item_id only appear once. If you build one-hot with 22,170 elements, there is a high possibility that the model will be overfitted when there are too many items with little data.\n",
    "\n",
    "Hashing is a possible technique that can be applied to <code>item_name</code>. Below is a simple implementation of hashing technique written in sklearn API with hash bucket number of 1000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>hashed_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!ABBYY FineReader 12 Professional Edition Full...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***В ЛУЧАХ СЛАВЫ   (UNV)                    D</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>***ГОЛУБАЯ ВОЛНА  (Univ)                      D</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***КОРОБКА (СТЕКЛО)                       D</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           item_name  item_id  \\\n",
       "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
       "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
       "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
       "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
       "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
       "\n",
       "   item_category_id  hashed_item  \n",
       "0                40          252  \n",
       "1                76          812  \n",
       "2                40          198  \n",
       "3                40          584  \n",
       "4                40          210  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def hash_modulo(val, mod):\n",
    "    md5 = hashlib.md5()  # can be other deterministic hash functions\n",
    "    md5.update(str(val).encode())\n",
    "    return int(md5.hexdigest(), 16) % mod\n",
    "\n",
    "\n",
    "class FeatureHasher(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_buckets: int):\n",
    "        self.num_buckets = num_buckets\n",
    "\n",
    "    def fit(self, X: pd.Series):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.Series):\n",
    "        return X.apply(lambda x: hash_modulo(x, self.num_buckets))\n",
    "\n",
    "\n",
    "fh = FeatureHasher(num_buckets=1000)\n",
    "\n",
    "df_items[\"hashed_item\"] = fh.transform(df_items[\"item_name\"])\n",
    "df_items.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
